{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing_wider_person.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1ltKO6FzL3ZKrlpw9aPUNFR8wlJEgcRcV","authorship_tag":"ABX9TyM4irA63EbuBt018XOqbVpN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"HGDZzg9p_s9I","colab_type":"code","colab":{}},"source":["%cd ../../../../../content/sample_data/\n","!git clone https://github.com/Yannick947/WiderPerson.git\n","%cd /../.."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ogyVuGKwtxB4","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import os\n","import csv\n","import time\n","import shutil\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0_YVA9on4uE","colab_type":"text"},"source":["# Constants"]},{"cell_type":"code","metadata":{"id":"xPf7QJFuz6PN","colab_type":"code","colab":{}},"source":["HEADER = ['image_name', 'x_min', 'y_min', 'x_max', 'y_max', 'label']\n","\n","\n","%cd ../../../../../../\n","annot_path = './content/drive/My Drive/person_detection/WiderPerson/Annotations'\n","images_path = ',/content/drive/My Drive/person_detection/WiderPerson/Images'\n","images_path_sample = '/content/sample_data/WiderPerson/Images'\n","\n","annot_csv_path = '/content/drive/My Drive/person_detection/keras-retinanet/annotations_sampledata.csv'\n","keras_path = '/content/drive/My Drive/person_detection/keras-retinanet'\n","#Remove classes which shall be left out in the csv\n","classes_ids = {1:'pedestrian',\n","               3:'partially-visible'}\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zCZ4qK_YoF6f","colab_type":"text"},"source":["# Preprocessing\n"]},{"cell_type":"code","metadata":{"id":"a6MjPOjOmWPm","colab_type":"code","colab":{}},"source":["%cd ../../../\n","def filter_images_by_size(df, max_size=4000, min_size=440):\n","  start_size = len(os.listdir(images_path_sample))\n","  for image_name in os.listdir(images_path_sample):\n","    try: \n","      image = read_image_bgr(images_path_sample + '/' + image_name)\n","      if (min(image.shape[0:2]) < min_size) or (max(image.shape[0:2]) > max_size):\n","        df = df[~df.image_name.str.contains(image_name)]\n","    except: \n","      print('Image not in dataset. Name of file: ', image_name)\n","  print('final df shape: ', df.shape)\n","  print('Removed ',start_size - df.image_name.nunique() , 'images')\n","  return df\n","\n","df = pd.read_csv(annot_csv_path,\n","                  header=None,\n","                  names=['image_name', 'x1', 'y1', 'x2', 'y2', 'label'])\n","\n","df_filtered = filter_images_by_size(df, min_size=600, max_size = 4000)\n","df_filtered.to_csv(keras_path + '/' + 'annot_filtered_600_4000.csv', header=None, index=None)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CW3uaRtqETs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PC7PwIxmjdFQ","colab_type":"code","colab":{}},"source":["#create train test split based on image names, not on annotations\n","%cd ../../../../../\n","annotations = pd.read_csv('/content/drive/My Drive/person_detection/keras-retinanet/annot_filtered_600_4000.csv',\n","              header=None,\n","              names=HEADER)\n","image_names = pd.Series(os.listdir(images_path), name='image_names')\n","image_names = '/content/sample_data/WiderPerson/Images' + '/' + image_names\n","train_names, test_names = train_test_split(image_names, test_size=0.15)\n","train_df = annotations[annotations.image_name.isin(train_names)]\n","test_df = annotations[annotations.image_name.isin(test_names)]\n","print(train_df.shape, train_df.image_name.nunique(), test_df.image_name.nunique(), test_df.shape)\n","# print(train_annot.head())\n","\n","\n","train_df.to_csv(keras_path + '/annot_train_filtered_600_4000.csv', header=None, index=None)\n","test_df.to_csv(keras_path + '/annot_test_filtered_600_4000.csv', header=None, index=None)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m9Yq5V-Pv5VZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0C_yMdxe_xo","colab_type":"code","colab":{}},"source":["#remove other classes than pedestrian and make partially visible to pedestrian\n","def filter_classes(df):\n","  df_filtered= df.loc[(df.label == 'pedestrian') | (df.label == 'partially-visible')]\n","  df_filtered.replace(to_replace='partially-visible', value='pedestrian', inplace=True)\n","  print('reduced from ', df.shape, 'to', df_filtered.shape)\n","  return df_filtered\n","\n","df = pd.read_csv(keras_path + '/' + 'annot_test_filtered_600_2500.csv', \n","                 header=None, names=['image_name', 'x1', 'y1', 'x2', 'y2', 'label'])\n","df_filtered = filter_classes(df)\n","df_filtered.to_csv(keras_path + '/' + 'annot_test_600_2500_classes_filtered.csv', header=None, index=None) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ebG-j_vKqCtn","colab_type":"code","colab":{}},"source":["shapes_x = list()\n","shapes_y = list()\n","for i in range(200):\n","  path = annot_test.iloc[i].image_name\n","  image = read_image_bgr(path)\n","  shapes_x.append(image.shape[0])\n","  shapes_y.append(image.shape[1])\n","print(shapes_x[0:10])\n","print(shapes_y[0:10])\n","print('average in x', sum(shapes_x) / len(shapes_x))\n","print('average in y', sum(shapes_y) / len(shapes_y))\n","print('std in x', np.std(shapes_x), '\\nstd in y', np.std(shapes_y))\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wke5ZRz6NSc3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F-pPvHfx3GFU","colab_type":"code","colab":{}},"source":["def replace_annoation_folder(new_path, csv_annot_path, img_path):\n","  '''Start this function from folder root, otherwise wont work properly'''\n","\n","  df_annot = pd.read_csv('/content/annotations_sample.csv',\n","                         names=HEADER)\n","  df_annot = df_annot.reset_index().drop(0).drop(columns='index')\n","  df_annot['name'] = df_annot['name'].str.replace(img_path, new_path)\n","  df_annot = df_annot.dropna()\n","  df_annot.to_csv(csv_annot_path + '/annotations_sampledata.csv',\n","                  index=None, header=None)\n","  return\n","\n","new_path = '/content/sample_data/WiderPerson/Images'\n","path_to_csv_annot = '/content/drive/My Drive/person_detection/keras-retinanet/annotations'\n","old_path = '/content/drive/My Drive/PersonDetection/WiderPerson/Images'\n","replace_annoation_folder(new_path, path_to_csv_annot, old_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uYHaD_Ho59t_","colab_type":"code","colab":{}},"source":["\n","def generate_annotations():\n","  # Generate the classes csv file\n","  annot = os.listdir(annot_path)\n","  with open(keras_path + '/annotations.csv', newline='', mode='x') as csvfile:\n","    csv_writer = csv.writer(csvfile, delimiter=',')\n","    for filename in os.listdir(images_path_sample)[0:10]:\n","      if str(filename + '.txt') in annot:\n","        f = open(annot_path + '/' +  filename + '.txt', 'r')\n","        \n","        for index, line in enumerate(f): \n","          if index == 0: \n","            if line.strip() == '0':\n","              print('Not any  object in the image!')\n","            continue\n","            \n","          else: \n","            split_line = line[:line.find('/')].split(' ')\n","            first_char = split_line.pop(0)\n","            split_line.insert(len(split_line), first_char)\n","            split_line.insert(0, images_path + '/' + filename)\n","            #convert from index to class label \n","            try:\n","              split_line[-1] = classes_ids[int(split_line[-1])]\n","            except: \n","              continue\n","            split_line[0] = split_line[0]\n","\n","            csv_writer.writerow(split_line)\n","        \n","        f.close()\n","  return\n","\n","generate_annotations()\n","#Check for wrongly annotaded bounding boxes\n","path = '/content/drive/My Drive/person_detection/keras-retinanet/annotations.csv'\n","\n","def check_bb(path):\n","  colnames = ['filename', 'x1', 'y1', 'x2', 'y2', 'class_label']\n","  df = pd.read_csv(path, names=colnames)\n","  df_new = df.loc[(df.x1 < df.x2) & (df.y1 < df.y2), : ]\n","  print ('Reduces shape from ', df.shape, 'to ', df_new.shape)\n","  return df_new"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZ2y1vj4vnDB","colab_type":"code","colab":{}},"source":["#create indexing csv file\n","with open('classes.csv', newline='', mode='x') as csvfile:\n","  csv_writer = csv.writer(csvfile, delimiter=',')\n","  for index, key in enumerate(classes_ids.keys()):\n","    csv_writer.writerow([str(classes_ids[key]), index])\n","    \n","#Check for wrongly annotaded bounding boxes\n","def check_bb(path):\n","  colnames = ['filename', 'x1', 'y1', 'x2', 'y2', 'class_label']\n","  df = pd.read_csv(path, names=colnames)\n","  df_new = df.loc[(df.x1 < df.x2) & (df.y1 < df.y2), : ]\n","  print ('Reduces shape from ', df.shape, 'to ', df_new.shape)\n","  return df_new\n","\n","df = check_bb(path)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"luvzzngloHwF","colab_type":"code","colab":{}},"source":["def show_image_objects(image_rows):\n","  image = read_image_bgr(image_rows.iloc[0].image_name)\n","  draw = image.copy()\n","\n","  for image_row in image_rows.itertuples():\n","    box = [image_row.x_min, image_row.y_min, image_row.x_max, image_row.y_max]\n","    draw_box(draw, box, color=(255, 255, 0))\n","  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n","\n","  plt.axis('off')\n","  plt.imshow(draw)\n","  plt.show()\n","\n","i = 3000\n","image_rows = annot_test[annot_test.image_name == annot_test.image_name.iloc[i]]\n","show_image_objects(image_rows)"],"execution_count":0,"outputs":[]}]}