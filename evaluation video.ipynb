{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"evaluation video.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1BIKSaWDTJxvmbJZ1PtfvWelVpQym1Prm","authorship_tag":"ABX9TyMzDJQ0QmytIDXcVkyAxWJc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"44HMfawIw58z","colab_type":"code","colab":{}},"source":["!pip install --upgrade keras\n","!pip install gdown\n","!pip install tensorflow-gpu==1.15"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ySErrmANu7I6","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"uxiK19ItuL7x","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/person_detection/keras-retinanet\n","\n","!pip install .\n","!python setup.py build_ext --inplace\n","%cd ../../../../../"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ogyVuGKwtxB4","colab_type":"code","colab":{}},"source":["import keras\n","from keras_retinanet import models\n","from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n","from keras_retinanet.utils.visualization import draw_box, draw_caption\n","from keras_retinanet.utils.colors import label_color\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import numpy as np\n","import time\n","from google.colab.patches import cv2_imshow\n","import tensorflow as tf\n","import pandas as pd\n","\n","def get_session():\n","    config = tf.compat.v1.ConfigProto()\n","    config.gpu_options.allow_growth = True\n","    return tf.compat.v1.Session(config=config)\n","\n","keras.backend.tensorflow_backend.set_session(get_session())\n","\n","model_path = '/content/drive/My Drive/person_detection/keras-retinanet/snapshots/13-04-2020_103546_resnet152_13_0.h5'    \n","model = models.load_model(model_path, backbone_name='resnet152')\n","model = models.convert_model(model)\n","labels_to_names = {0: 'pedestrian'}                                     \n","\n","video_path = '/content/drive/My Drive/person_detection/bus_showcase.avi'  \n","output_path = '/content/drive/My Drive/person_detection/bus_showcase_detected.mp4' \n","fps = 20\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHZutf64zB-0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jua7Hr0A72a8","colab_type":"text"},"source":["# Creating the new feature dataframe with detections\n"]},{"cell_type":"code","metadata":{"id":"hNqRqS-DHOzW","colab_type":"code","colab":{}},"source":["vcapture = cv2.VideoCapture(video_path)\n","\n","width = int(vcapture.get(cv2.CAP_PROP_FRAME_WIDTH))  # uses given video width and height\n","height = int(vcapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","vwriter = cv2.VideoWriter(output_path,cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height)) #\n","print('width: ', width, 'height: ', height)\n","num_frames = int(vcapture.get(cv2.CAP_PROP_FRAME_COUNT))\n","min_side_factor = 2 \n","\n","def run_detection_video(video_path):\n","    downscale_factor_y = 2\n","    df_detections = create_zeroed_df(downscale_factor_y, num_frames)\n","\n","    frame_index = 0\n","    success = True\n","    start = time.time()\n","\n","    while success:\n","        if frame_index % 100 == 0:\n","            print(\"frame: \", frame_index)\n","        frame_index += 1\n","        # Read next image\n","        success, image = vcapture.read()\n","\n","        if success:\n","\n","            draw = image.copy()\n","            draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n","\n","            image = preprocess_image(image)\n","            image, scale = resize_image(image, min_side=width * min_side_factor, max_side=1333)\n","            boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n","            boxes /= scale\n","\n","            for box, score, label in zip(boxes[0], scores[0], labels[0]):\n","                # scores are sorted so we can break\n","                if score < 0.35:\n","                    break\n","\n","                color = label_color(label)\n","\n","                b = box.astype(int)\n","                draw_box(draw, b, color=color)\n","\n","                #fill df with probability at the center of y axis, consider rezizing with min_side_factor\n","\n","                df_detections.iloc[frame_index, int((b[3] + b[1]) / min_side_factor / 2 )] = score\n","\n","                caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n","                draw_caption(draw, b, caption)\n","            detected_frame = cv2.cvtColor(draw, cv2.COLOR_RGB2BGR)\n","            vwriter.write(detected_frame)  # overwrites video slice\n","\n","    vcapture.release()\n","    vwriter.release()  \n","    end = time.time()\n","    df_detections.to_csv('video_detection.csv', header=None)\n","    print(\"Total Time: \", end - start)\n","\n","run_detection_video(video_path)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hCGxQmPm8648","colab_type":"code","colab":{}},"source":["def create_zeroed_df(factor_y, num_frames):\n","  return pd.DataFrame(np.zeros((num_frames, int(height / factor_y))))\n"],"execution_count":0,"outputs":[]}]}